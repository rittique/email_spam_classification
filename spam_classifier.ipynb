{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4aacb26-dbbb-497b-9339-a1cbf56f09bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rittique/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rittique/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from joblib import load\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "import joblib\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28ecbf8f-0fa5-42f1-8b69-dadd4a3609fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test.csv', 'train.csv', '.ipynb_checkpoints', 'sample_submission.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Path to the directory where the data is saved\n",
    "data_path = \"./data/\"\n",
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c684e2a4-9fd6-4f21-80c9-09c12eba4997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Training Set: 60000\n",
      "Size of Testing Set: 40632\n",
      "Length of Training Set: 15000\n",
      "Length of Testing Set: 13544\n"
     ]
    }
   ],
   "source": [
    "train_data = os.path.join(data_path, os.listdir(data_path)[1])\n",
    "test_data = os.path.join(data_path, os.listdir(data_path)[0])\n",
    "\n",
    "df_train = pd.read_csv(train_data)\n",
    "df_test = pd.read_csv(test_data)\n",
    "\n",
    "print(f\"Size of Training Set: {df_train.size}\")\n",
    "print(f\"Size of Testing Set: {df_test.size}\")\n",
    "\n",
    "print(f\"Length of Training Set: {len(df_train)}\")\n",
    "print(f\"Length of Testing Set: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5144ba74-67a7-49e8-8c43-7881e79af0f1",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "593ed0a3-88e9-45f9-b296-5df91ac67bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subject_and_email(df):\n",
    "    subjects = []\n",
    "    bodies = []\n",
    "    for i in range(len(df)):\n",
    "        subjects.append(df.email[i].split(\"\\n\")[0].split(\"Subject: \")[1])\n",
    "        bodies.append(\" \".join(df.email[i].split(\"\\n\")[1:]))\n",
    "\n",
    "    df[\"subjects\"] = subjects\n",
    "    df[\"email_bodies\"] = bodies\n",
    "\n",
    "    return df\n",
    "\n",
    "def email_check(df):\n",
    "    has_email_id = []\n",
    "    for i in range(len(df)):\n",
    "        if \" @ \" and \" . com\" in df.email_bodies[i]:\n",
    "            has_email_id.append(1)\n",
    "        else:\n",
    "            has_email_id.append(0)\n",
    "    \n",
    "    return has_email_id\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove URLs with gaps\n",
    "    text = re.sub(r'https\\s+www\\s+\\S+\\s+\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'www\\s+\\S+\\s+\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove emails with gaps\n",
    "    text = re.sub(r'\\S+\\s+\\S+\\s+@\\s+\\S+\\s+\\S+', '', text)\n",
    "    \n",
    "    # Remove phone numbers (adjust pattern if needed)\n",
    "    text = re.sub(r'\\b\\d{10,15}\\b', '', text)\n",
    "    \n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    return ' '.join(words)\n",
    "\n",
    "def complete_preprocessing(df):\n",
    "    df = extract_subject_and_email(df)\n",
    "    df[\"has_email_id\"] = email_check(df)\n",
    "    df[\"subjects\"] = df[\"subjects\"].apply(lambda x: clean_text(x))\n",
    "    df[\"email_bodies\"] = df[\"email_bodies\"].apply(lambda x: clean_text(x))\n",
    "    \n",
    "    # Tfidf Vectorization\n",
    "    subject_tfidf = TfidfVectorizer(max_features=1000).fit_transform(df['subjects'])\n",
    "    email_tfidf = TfidfVectorizer(max_features=5000).fit_transform(df['email_bodies'])\n",
    "    \n",
    "    # Combine all features\n",
    "    X = hstack([subject_tfidf, email_tfidf, df[['source', 'has_email_id']].values])\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88c230d6-e967-488c-be69-075d5b0a3ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = complete_preprocessing(df_train)\n",
    "y_train = df_train['class']\n",
    "\n",
    "# Train-validation split 95% training and 5% validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5520c9-dc17-4720-81d6-7a9f23944222",
   "metadata": {},
   "source": [
    "# Training on base state of three Models: Random Forest, SVM, Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4562683f-f849-4d76-9650-84c8255e4102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest...\n",
      "\n",
      "Random Forest Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam       0.99      0.97      0.98       357\n",
      "        spam       0.97      0.99      0.98       393\n",
      "\n",
      "    accuracy                           0.98       750\n",
      "   macro avg       0.98      0.98      0.98       750\n",
      "weighted avg       0.98      0.98      0.98       750\n",
      "\n",
      "Random Forest Accuracy: 0.9800\n",
      "Training SVM...\n",
      "\n",
      "SVM Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam       0.99      0.97      0.98       357\n",
      "        spam       0.97      0.99      0.98       393\n",
      "\n",
      "    accuracy                           0.98       750\n",
      "   macro avg       0.98      0.98      0.98       750\n",
      "weighted avg       0.98      0.98      0.98       750\n",
      "\n",
      "SVM Accuracy: 0.9827\n",
      "Training Logistic Regression...\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam       0.99      0.97      0.98       357\n",
      "        spam       0.97      0.99      0.98       393\n",
      "\n",
      "    accuracy                           0.98       750\n",
      "   macro avg       0.98      0.98      0.98       750\n",
      "weighted avg       0.98      0.98      0.98       750\n",
      "\n",
      "Logistic Regression Accuracy: 0.9827\n"
     ]
    }
   ],
   "source": [
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    'Random Forest': RandomForestClassifier(class_weight='balanced'),\n",
    "    'SVM' : SVC(class_weight='balanced', random_state=42),\n",
    "    'Logistic Regression' : LogisticRegression(class_weight='balanced', solver='saga', max_iter=500, random_state=42)\n",
    "}\n",
    "\n",
    "# Train classifiers and evaluate\n",
    "for name, classifier in classifiers.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions and evaluation\n",
    "    y_pred = classifier.predict(X_val)\n",
    "    print(f\"\\n{name} Classification Report:\\n\")\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    print(f\"{name} Accuracy: {accuracy_score(y_val, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53cf6e0-351e-403e-8280-6898058f1068",
   "metadata": {},
   "source": [
    "### Doing Cross validation to check for model generalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33897486-3037-41c6-b792-596b2437003d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest...\n",
      "Random Forest Cross-Validation Accuracy: 0.9817 ± 0.0026\n",
      "\n",
      "Random Forest Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam       0.99      0.98      0.98       357\n",
      "        spam       0.98      0.99      0.98       393\n",
      "\n",
      "    accuracy                           0.98       750\n",
      "   macro avg       0.98      0.98      0.98       750\n",
      "weighted avg       0.98      0.98      0.98       750\n",
      "\n",
      "Random Forest Accuracy: 0.9827\n",
      "\n",
      "Training SVM...\n",
      "SVM Cross-Validation Accuracy: 0.9818 ± 0.0025\n",
      "\n",
      "SVM Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam       0.99      0.97      0.98       357\n",
      "        spam       0.97      0.99      0.98       393\n",
      "\n",
      "    accuracy                           0.98       750\n",
      "   macro avg       0.98      0.98      0.98       750\n",
      "weighted avg       0.98      0.98      0.98       750\n",
      "\n",
      "SVM Accuracy: 0.9827\n",
      "\n",
      "Training Logistic Regression...\n",
      "Logistic Regression Cross-Validation Accuracy: 0.9848 ± 0.0035\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam       0.99      0.97      0.98       357\n",
      "        spam       0.97      0.99      0.98       393\n",
      "\n",
      "    accuracy                           0.98       750\n",
      "   macro avg       0.98      0.98      0.98       750\n",
      "weighted avg       0.98      0.98      0.98       750\n",
      "\n",
      "Logistic Regression Accuracy: 0.9827\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Train classifiers and evaluate\n",
    "for name, classifier in classifiers.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(classifier, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "    print(f\"{name} Cross-Validation Accuracy: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
    "    \n",
    "    # Fit the classifier on the full training set\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions and evaluation\n",
    "    y_pred = classifier.predict(X_val)\n",
    "    print(f\"\\n{name} Classification Report:\\n\")\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    print(f\"{name} Accuracy: {accuracy_score(y_val, y_pred):.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b44609c-392c-40f8-97a2-0fb131cc5f84",
   "metadata": {},
   "source": [
    "### Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4175bdca-fa14-4657-9181-ab576a67f8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grids\n",
    "param_dist_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "param_dist_svc = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'degree': [2, 3, 4]  # Only for 'poly' kernel\n",
    "}\n",
    "\n",
    "param_dist_logreg = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'solver': ['saga'],\n",
    "    'l1_ratio': [0.1, 0.5, 0.7]  # Only relevant when 'penalty' is 'elasticnet'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ffa1231-e183-4dcb-952a-3f4dfbdbb0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomizedSearchCV for RandomForest\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    estimator=RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "    param_distributions=param_dist_rf,\n",
    "    n_iter=50,  # Number of different combinations to try\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# RandomizedSearchCV for SVC\n",
    "random_search_svc = RandomizedSearchCV(\n",
    "    estimator=SVC(class_weight='balanced', random_state=42),\n",
    "    param_distributions=param_dist_svc,\n",
    "    n_iter=50,  # Number of different combinations to try\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# RandomizedSearchCV for LogisticRegression\n",
    "random_search_logreg = RandomizedSearchCV(\n",
    "    estimator=LogisticRegression(class_weight='balanced', max_iter=500, random_state=42),\n",
    "    param_distributions=param_dist_logreg,\n",
    "    n_iter=50,  # Number of different combinations to try\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0ee7e9d-124d-497c-aee2-cdb837522872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Random Forest...\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best parameters for Random Forest: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': None, 'bootstrap': False}\n",
      "Best cross-validation score for Random Forest: 0.9848\n",
      "\n",
      "Tuning SVM...\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best parameters for SVM: {'kernel': 'rbf', 'gamma': 0.1, 'degree': 4, 'C': 10}\n",
      "Best cross-validation score for SVM: 0.9869\n",
      "\n",
      "Tuning Logistic Regression...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:305: UserWarning: The total space of parameters 36 is smaller than n_iter=50. Running 36 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression: {'solver': 'saga', 'penalty': 'l2', 'l1_ratio': 0.1, 'C': 100}\n",
      "Best cross-validation score for Logistic Regression: 0.9867\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuning Random Forest...\")\n",
    "random_search_rf.fit(X_train, y_train)\n",
    "print(f\"Best parameters for Random Forest: {random_search_rf.best_params_}\")\n",
    "print(f\"Best cross-validation score for Random Forest: {random_search_rf.best_score_:.4f}\\n\")\n",
    "\n",
    "print(\"Tuning SVM...\")\n",
    "random_search_svc.fit(X_train, y_train)\n",
    "print(f\"Best parameters for SVM: {random_search_svc.best_params_}\")\n",
    "print(f\"Best cross-validation score for SVM: {random_search_svc.best_score_:.4f}\\n\")\n",
    "\n",
    "print(\"Tuning Logistic Regression...\")\n",
    "random_search_logreg.fit(X_train, y_train)\n",
    "print(f\"Best parameters for Logistic Regression: {random_search_logreg.best_params_}\")\n",
    "print(f\"Best cross-validation score for Logistic Regression: {random_search_logreg.best_score_:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "489df12e-cf58-4497-a9ab-3f6f787f5947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Test Set Evaluation:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam       0.99      0.97      0.98       357\n",
      "        spam       0.98      0.99      0.98       393\n",
      "\n",
      "    accuracy                           0.98       750\n",
      "   macro avg       0.98      0.98      0.98       750\n",
      "weighted avg       0.98      0.98      0.98       750\n",
      "\n",
      "Random Forest Test Accuracy: 0.9827\n",
      "\n",
      "SVM Test Set Evaluation:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam       1.00      0.98      0.99       357\n",
      "        spam       0.98      1.00      0.99       393\n",
      "\n",
      "    accuracy                           0.99       750\n",
      "   macro avg       0.99      0.99      0.99       750\n",
      "weighted avg       0.99      0.99      0.99       750\n",
      "\n",
      "SVM Test Accuracy: 0.9880\n",
      "\n",
      "Logistic Regression Test Set Evaluation:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam       0.99      0.97      0.98       357\n",
      "        spam       0.98      0.99      0.99       393\n",
      "\n",
      "    accuracy                           0.99       750\n",
      "   macro avg       0.99      0.98      0.99       750\n",
      "weighted avg       0.99      0.99      0.99       750\n",
      "\n",
      "Logistic Regression Test Accuracy: 0.9853\n",
      "\n",
      "Best Model Information:\n",
      " {'RandomForest': {'best_hyperparams': {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': None, 'bootstrap': False}, 'accuracy': 0.9826666666666667}, 'SVC': {'best_hyperparams': {'kernel': 'rbf', 'gamma': 0.1, 'degree': 4, 'C': 10}, 'accuracy': 0.988}, 'LogisticRegression': {'best_hyperparams': {'solver': 'saga', 'penalty': 'l2', 'l1_ratio': 0.1, 'C': 100}, 'accuracy': 0.9853333333333333}}\n"
     ]
    }
   ],
   "source": [
    "# Dictionaries to store best hyperparameters and accuracy\n",
    "best_hyperparams_rf = {}\n",
    "best_hyperparams_svc = {}\n",
    "best_hyperparams_logreg = {}\n",
    "\n",
    "accuracy_rf = 0.0\n",
    "accuracy_svc = 0.0\n",
    "accuracy_logreg = 0.0\n",
    "\n",
    "# Evaluate the best RandomForest model\n",
    "best_rf = random_search_rf.best_estimator_\n",
    "best_hyperparams_rf = random_search_rf.best_params_\n",
    "y_pred_rf = best_rf.predict(X_val)\n",
    "accuracy_rf = accuracy_score(y_val, y_pred_rf)\n",
    "print(\"\\nRandom Forest Test Set Evaluation:\\n\")\n",
    "print(classification_report(y_val, y_pred_rf))\n",
    "print(f\"Random Forest Test Accuracy: {accuracy_rf:.4f}\")\n",
    "\n",
    "# Evaluate the best SVC model\n",
    "best_svc = random_search_svc.best_estimator_\n",
    "best_hyperparams_svc = random_search_svc.best_params_\n",
    "y_pred_svc = best_svc.predict(X_val)\n",
    "accuracy_svc = accuracy_score(y_val, y_pred_svc)\n",
    "print(\"\\nSVM Test Set Evaluation:\\n\")\n",
    "print(classification_report(y_val, y_pred_svc))\n",
    "print(f\"SVM Test Accuracy: {accuracy_svc:.4f}\")\n",
    "\n",
    "# Evaluate the best Logistic Regression model\n",
    "best_logreg = random_search_logreg.best_estimator_\n",
    "best_hyperparams_logreg = random_search_logreg.best_params_\n",
    "y_pred_logreg = best_logreg.predict(X_val)\n",
    "accuracy_logreg = accuracy_score(y_val, y_pred_logreg)\n",
    "print(\"\\nLogistic Regression Test Set Evaluation:\\n\")\n",
    "print(classification_report(y_val, y_pred_logreg))\n",
    "print(f\"Logistic Regression Test Accuracy: {accuracy_logreg:.4f}\")\n",
    "\n",
    "# Store the best accuracy and hyperparameters for each model\n",
    "best_model_info = {\n",
    "    'RandomForest': {'best_hyperparams': best_hyperparams_rf, 'accuracy': accuracy_rf},\n",
    "    'SVC': {'best_hyperparams': best_hyperparams_svc, 'accuracy': accuracy_svc},\n",
    "    'LogisticRegression': {'best_hyperparams': best_hyperparams_logreg, 'accuracy': accuracy_logreg}\n",
    "}\n",
    "\n",
    "print(\"\\nBest Model Information:\\n\", best_model_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6fa96dde-f3c6-40d6-a9b3-44c3098cf055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model and results saved successfully.\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   3.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   6.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   4.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   4.0s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   7.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   5.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   6.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   4.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   6.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  12.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  11.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  11.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   4.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.5s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   6.9s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   6.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   5.6s\n",
      "[CV] END ........C=100, degree=2, gamma=0.001, kernel=linear; total time=  10.0s\n",
      "[CV] END ............C=0.1, degree=3, gamma=0.01, kernel=rbf; total time= 1.2min\n",
      "[CV] END .............C=1, degree=3, gamma=0.01, kernel=poly; total time= 1.4min\n",
      "[CV] END .............C=1, degree=3, gamma=0.01, kernel=poly; total time= 1.4min\n",
      "[CV] END ............C=0.1, degree=3, gamma=1, kernel=linear; total time=  27.4s\n",
      "[CV] END ...........C=1, degree=4, gamma=0.01, kernel=linear; total time=  15.0s\n",
      "[CV] END .........C=0.1, degree=3, gamma=0.01, kernel=linear; total time=  27.3s\n",
      "[CV] END ............C=10, degree=3, gamma=0.001, kernel=rbf; total time=  53.4s\n",
      "[CV] END ...............C=100, degree=4, gamma=1, kernel=rbf; total time= 3.3min\n",
      "[CV] END ..........C=0.1, degree=2, gamma=0.001, kernel=poly; total time= 1.7min\n",
      "[CV] END ..........C=0.1, degree=2, gamma=0.001, kernel=poly; total time= 1.7min\n",
      "[CV] END ............C=100, degree=2, gamma=0.1, kernel=poly; total time=  12.6s\n",
      "[CV] END ..............C=1, degree=3, gamma=0.01, kernel=rbf; total time=  49.7s\n",
      "[CV] END ........C=0.1, degree=2, gamma=0.001, kernel=linear; total time=  26.0s\n",
      "[CV] END ..............C=0.1, degree=4, gamma=1, kernel=poly; total time=  23.0s\n",
      "[CV] END .............C=100, degree=3, gamma=0.1, kernel=rbf; total time=  20.0s\n",
      "[CV] END ............C=0.1, degree=4, gamma=0.01, kernel=rbf; total time= 1.3min\n",
      "[CV] END .............C=0.1, degree=3, gamma=0.1, kernel=rbf; total time=  59.2s\n",
      "[CV] END .........C=10, degree=3, gamma=0.001, kernel=linear; total time=  11.9s\n",
      "[CV] END ..........C=100, degree=2, gamma=0.1, kernel=linear; total time=  12.3s\n",
      "[CV] END ..........C=100, degree=2, gamma=0.1, kernel=linear; total time=  12.2s\n",
      "[CV] END ...........C=1, degree=2, gamma=0.01, kernel=linear; total time=  13.7s\n",
      "[CV] END ............C=100, degree=3, gamma=0.01, kernel=rbf; total time=  14.6s\n",
      "[CV] END .............C=10, degree=4, gamma=1, kernel=linear; total time=  12.9s\n",
      "[CV] END ..............C=1, degree=4, gamma=1, kernel=linear; total time=  14.0s\n",
      "[CV] END ............C=0.1, degree=2, gamma=1, kernel=linear; total time=  25.6s\n",
      "[CV] END ...............C=1, degree=2, gamma=0.1, kernel=rbf; total time=  26.9s\n",
      "[CV] END ...............C=10, degree=3, gamma=1, kernel=poly; total time=  15.0s\n",
      "[CV] END ...............C=10, degree=3, gamma=1, kernel=poly; total time=  14.3s\n",
      "[CV] END ............C=0.1, degree=4, gamma=1, kernel=linear; total time=  25.6s\n",
      "[CV] END ..........C=0.1, degree=3, gamma=0.001, kernel=poly; total time= 1.7min\n",
      "[CV] END .......C=0.1, l1_ratio=0.1, penalty=l1, solver=saga; total time=   2.3s\n",
      "[CV] END C=0.1, l1_ratio=0.1, penalty=elasticnet, solver=saga; total time=  23.8s\n",
      "[CV] END .........C=1, l1_ratio=0.1, penalty=l1, solver=saga; total time=  15.9s\n",
      "[CV] END .........C=1, l1_ratio=0.5, penalty=l1, solver=saga; total time=  16.6s\n",
      "[CV] END .........C=1, l1_ratio=0.5, penalty=l1, solver=saga; total time=  17.3s\n",
      "[CV] END .C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga; total time=  20.6s\n",
      "[CV] END .C=1, l1_ratio=0.7, penalty=elasticnet, solver=saga; total time=  20.7s\n",
      "[CV] END ........C=10, l1_ratio=0.1, penalty=l1, solver=saga; total time= 1.1min\n",
      "[CV] END ........C=10, l1_ratio=0.5, penalty=l1, solver=saga; total time= 1.0min\n",
      "[CV] END ........C=10, l1_ratio=0.5, penalty=l2, solver=saga; total time=   2.6s\n",
      "[CV] END ........C=10, l1_ratio=0.5, penalty=l2, solver=saga; total time=   2.6s\n",
      "[CV] END ........C=10, l1_ratio=0.5, penalty=l2, solver=saga; total time=   2.5s\n",
      "[CV] END ........C=10, l1_ratio=0.5, penalty=l2, solver=saga; total time=   2.6s\n",
      "[CV] END ........C=10, l1_ratio=0.5, penalty=l2, solver=saga; total time=   2.3s\n",
      "[CV] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga; total time= 2.2min\n",
      "[CV] END ........C=10, l1_ratio=0.7, penalty=l2, solver=saga; total time=   2.7s\n",
      "[CV] END ........C=10, l1_ratio=0.7, penalty=l2, solver=saga; total time=   2.6s\n",
      "[CV] END ........C=10, l1_ratio=0.7, penalty=l2, solver=saga; total time=   2.6s\n",
      "[CV] END ........C=10, l1_ratio=0.7, penalty=l2, solver=saga; total time=   2.8s\n",
      "[CV] END ........C=10, l1_ratio=0.7, penalty=l2, solver=saga; total time=   2.0s\n",
      "[CV] END C=10, l1_ratio=0.7, penalty=elasticnet, solver=saga; total time= 1.7min\n",
      "[CV] END .......C=100, l1_ratio=0.1, penalty=l1, solver=saga; total time= 2.9min\n",
      "[CV] END .......C=100, l1_ratio=0.5, penalty=l1, solver=saga; total time= 2.9min\n",
      "[CV] END C=100, l1_ratio=0.5, penalty=elasticnet, solver=saga; total time= 3.7min\n",
      "[CV] END C=100, l1_ratio=0.7, penalty=elasticnet, solver=saga; total time= 3.0min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   3.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   3.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   6.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   6.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   4.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   4.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   7.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   3.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   6.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   7.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   7.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   3.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   3.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  11.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  11.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   5.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   4.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   6.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   7.0s\n",
      "[CV] END ............C=0.1, degree=3, gamma=0.01, kernel=rbf; total time= 1.2min\n",
      "[CV] END ................C=10, degree=4, gamma=1, kernel=rbf; total time= 3.1min\n",
      "[CV] END ............C=100, degree=4, gamma=1, kernel=linear; total time=  12.4s\n",
      "[CV] END ..............C=1, degree=4, gamma=0.1, kernel=poly; total time=  21.3s\n",
      "[CV] END .........C=0.1, degree=3, gamma=0.01, kernel=linear; total time=  27.5s\n",
      "[CV] END ............C=1, degree=3, gamma=0.1, kernel=linear; total time=  14.3s\n",
      "[CV] END ............C=10, degree=3, gamma=0.001, kernel=rbf; total time=  54.4s\n",
      "[CV] END ..............C=10, degree=4, gamma=0.1, kernel=rbf; total time=  20.5s\n",
      "[CV] END ...............C=1, degree=4, gamma=0.1, kernel=rbf; total time=  27.7s\n",
      "[CV] END ...............C=1, degree=4, gamma=0.1, kernel=rbf; total time=  28.0s\n",
      "[CV] END ..........C=0.1, degree=4, gamma=0.1, kernel=linear; total time=  27.9s\n",
      "[CV] END ..........C=0.1, degree=4, gamma=0.1, kernel=linear; total time=  27.1s\n",
      "[CV] END ..........C=1, degree=4, gamma=0.001, kernel=linear; total time=  14.4s\n",
      "[CV] END ............C=100, degree=3, gamma=0.1, kernel=poly; total time=  13.3s\n",
      "[CV] END ................C=10, degree=2, gamma=1, kernel=rbf; total time= 3.1min\n",
      "[CV] END ..............C=100, degree=2, gamma=1, kernel=poly; total time=  14.2s\n",
      "[CV] END ..............C=100, degree=2, gamma=1, kernel=poly; total time=  12.7s\n",
      "[CV] END ..............C=100, degree=2, gamma=1, kernel=poly; total time=  12.9s\n",
      "[CV] END ............C=100, degree=2, gamma=0.1, kernel=poly; total time=  12.7s\n",
      "[CV] END ..............C=1, degree=3, gamma=0.01, kernel=rbf; total time=  49.7s\n",
      "[CV] END ........C=0.1, degree=2, gamma=0.001, kernel=linear; total time=  26.2s\n",
      "[CV] END ..............C=0.1, degree=4, gamma=1, kernel=poly; total time=  21.0s\n",
      "[CV] END ..............C=0.1, degree=4, gamma=1, kernel=poly; total time=  14.9s\n",
      "[CV] END .............C=100, degree=3, gamma=0.1, kernel=rbf; total time=  20.5s\n",
      "[CV] END ...............C=10, degree=4, gamma=1, kernel=poly; total time=  16.3s\n",
      "[CV] END ...............C=10, degree=4, gamma=1, kernel=poly; total time=  14.3s\n",
      "[CV] END ..............C=1, degree=2, gamma=1, kernel=linear; total time=  14.0s\n",
      "[CV] END ..............C=1, degree=2, gamma=1, kernel=linear; total time=  13.8s\n",
      "[CV] END .............C=0.1, degree=3, gamma=0.1, kernel=rbf; total time= 1.0min\n",
      "[CV] END .........C=10, degree=3, gamma=0.001, kernel=linear; total time=  12.2s\n",
      "[CV] END .........C=10, degree=3, gamma=0.001, kernel=linear; total time=  11.6s\n",
      "[CV] END ..........C=100, degree=2, gamma=0.1, kernel=linear; total time=  12.3s\n",
      "[CV] END ..........C=100, degree=2, gamma=0.1, kernel=linear; total time=  12.1s\n",
      "[CV] END ...........C=100, degree=2, gamma=0.001, kernel=rbf; total time=  20.2s\n",
      "[CV] END ............C=100, degree=3, gamma=0.01, kernel=rbf; total time=  14.6s\n",
      "[CV] END .............C=10, degree=4, gamma=1, kernel=linear; total time=  12.2s\n",
      "[CV] END ............C=0.1, degree=2, gamma=1, kernel=linear; total time=  25.7s\n",
      "[CV] END .............C=0.1, degree=4, gamma=0.1, kernel=rbf; total time=  59.2s\n",
      "[CV] END ............C=0.1, degree=4, gamma=1, kernel=linear; total time=  25.9s\n",
      "[CV] END ..........C=0.1, degree=3, gamma=0.001, kernel=poly; total time= 1.7min\n",
      "[CV] END .......C=0.1, l1_ratio=0.1, penalty=l1, solver=saga; total time=   2.4s\n",
      "[CV] END .......C=0.1, l1_ratio=0.5, penalty=l1, solver=saga; total time=   2.1s\n",
      "[CV] END .......C=0.1, l1_ratio=0.5, penalty=l2, solver=saga; total time=   0.9s\n",
      "[CV] END .......C=0.1, l1_ratio=0.5, penalty=l2, solver=saga; total time=   1.0s\n",
      "[CV] END .......C=0.1, l1_ratio=0.5, penalty=l2, solver=saga; total time=   0.9s\n",
      "[CV] END C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga; total time=   4.5s\n",
      "[CV] END C=0.1, l1_ratio=0.5, penalty=elasticnet, solver=saga; total time=   4.6s\n",
      "[CV] END .......C=0.1, l1_ratio=0.7, penalty=l1, solver=saga; total time=   2.0s\n",
      "[CV] END .......C=0.1, l1_ratio=0.7, penalty=l2, solver=saga; total time=   1.2s\n",
      "[CV] END C=0.1, l1_ratio=0.7, penalty=elasticnet, solver=saga; total time=   2.5s\n",
      "[CV] END C=0.1, l1_ratio=0.7, penalty=elasticnet, solver=saga; total time=   2.4s\n",
      "[CV] END .........C=1, l1_ratio=0.1, penalty=l1, solver=saga; total time=  15.8s\n",
      "[CV] END .C=1, l1_ratio=0.1, penalty=elasticnet, solver=saga; total time=  46.5s\n",
      "[CV] END .........C=1, l1_ratio=0.7, penalty=l1, solver=saga; total time=  18.7s\n",
      "[CV] END ........C=10, l1_ratio=0.1, penalty=l1, solver=saga; total time= 1.1min\n",
      "[CV] END ........C=10, l1_ratio=0.5, penalty=l1, solver=saga; total time= 1.0min\n",
      "[CV] END ........C=10, l1_ratio=0.5, penalty=l1, solver=saga; total time= 1.1min\n",
      "[CV] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga; total time= 2.3min\n",
      "[CV] END .......C=100, l1_ratio=0.1, penalty=l1, solver=saga; total time= 2.9min\n",
      "[CV] END C=100, l1_ratio=0.1, penalty=elasticnet, solver=saga; total time= 4.1min\n",
      "[CV] END C=100, l1_ratio=0.5, penalty=elasticnet, solver=saga; total time= 3.6min\n",
      "[CV] END C=100, l1_ratio=0.7, penalty=elasticnet, solver=saga; total time= 3.0min\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   3.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   3.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   6.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   6.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   8.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   3.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   4.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   1.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   5.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=300; total time=   6.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   7.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=   6.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   3.9s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  13.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=  13.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  11.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   4.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   7.0s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   6.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   5.5s\n",
      "[CV] END ............C=0.1, degree=3, gamma=0.01, kernel=rbf; total time= 1.2min\n",
      "[CV] END ................C=10, degree=4, gamma=1, kernel=rbf; total time= 3.2min\n",
      "[CV] END ............C=100, degree=4, gamma=1, kernel=linear; total time=  12.9s\n",
      "[CV] END ..............C=1, degree=4, gamma=0.1, kernel=poly; total time=  21.3s\n",
      "[CV] END ...........C=1, degree=4, gamma=0.01, kernel=linear; total time=  14.6s\n",
      "[CV] END ............C=1, degree=3, gamma=0.1, kernel=linear; total time=  14.7s\n",
      "[CV] END ..........C=10, degree=2, gamma=0.01, kernel=linear; total time=  12.4s\n",
      "[CV] END ............C=10, degree=3, gamma=0.001, kernel=rbf; total time=  54.1s\n",
      "[CV] END ..............C=10, degree=4, gamma=0.1, kernel=rbf; total time=  20.9s\n",
      "[CV] END ..............C=10, degree=4, gamma=0.1, kernel=rbf; total time=  20.3s\n",
      "[CV] END ...............C=1, degree=4, gamma=0.1, kernel=rbf; total time=  27.5s\n",
      "[CV] END ..........C=0.1, degree=4, gamma=0.1, kernel=linear; total time=  28.9s\n",
      "[CV] END ..........C=0.1, degree=4, gamma=0.1, kernel=linear; total time=  27.7s\n",
      "[CV] END ..........C=1, degree=4, gamma=0.001, kernel=linear; total time=  14.4s\n",
      "[CV] END ............C=100, degree=3, gamma=0.1, kernel=poly; total time=  13.1s\n",
      "[CV] END ................C=10, degree=2, gamma=1, kernel=rbf; total time= 3.1min\n",
      "[CV] END ..........C=100, degree=2, gamma=0.001, kernel=poly; total time= 1.3min\n",
      "[CV] END ..............C=1, degree=3, gamma=0.01, kernel=rbf; total time=  50.2s\n",
      "[CV] END .............C=0.1, degree=2, gamma=0.1, kernel=rbf; total time=  58.9s\n",
      "[CV] END ............C=0.1, degree=4, gamma=0.01, kernel=rbf; total time= 1.3min\n",
      "[CV] END ...........C=0.1, degree=2, gamma=0.001, kernel=rbf; total time= 1.4min\n",
      "[CV] END ...........C=1, degree=2, gamma=0.01, kernel=linear; total time=  14.0s\n",
      "[CV] END ...........C=100, degree=2, gamma=0.001, kernel=rbf; total time=  20.0s\n",
      "[CV] END ............C=100, degree=3, gamma=0.01, kernel=rbf; total time=  14.5s\n",
      "[CV] END ..............C=1, degree=4, gamma=1, kernel=linear; total time=  14.0s\n",
      "[CV] END ............C=0.1, degree=2, gamma=1, kernel=linear; total time=  25.6s\n",
      "[CV] END ...............C=1, degree=2, gamma=0.1, kernel=rbf; total time=  27.2s\n",
      "[CV] END ...............C=1, degree=2, gamma=0.1, kernel=rbf; total time=  27.5s\n",
      "[CV] END ............C=0.1, degree=4, gamma=1, kernel=linear; total time=  25.5s\n",
      "[CV] END ...............C=0.1, degree=4, gamma=1, kernel=rbf; total time= 1.5min\n",
      "[CV] END .......C=0.1, l1_ratio=0.1, penalty=l1, solver=saga; total time=   2.2s\n",
      "[CV] END C=0.1, l1_ratio=0.1, penalty=elasticnet, solver=saga; total time=  23.9s\n",
      "[CV] END .........C=1, l1_ratio=0.1, penalty=l1, solver=saga; total time=  15.8s\n",
      "[CV] END .........C=1, l1_ratio=0.5, penalty=l1, solver=saga; total time=  16.9s\n",
      "[CV] END .........C=1, l1_ratio=0.5, penalty=l2, solver=saga; total time=   1.0s\n",
      "[CV] END .........C=1, l1_ratio=0.5, penalty=l2, solver=saga; total time=   1.0s\n",
      "[CV] END .........C=1, l1_ratio=0.5, penalty=l2, solver=saga; total time=   0.9s\n",
      "[CV] END .........C=1, l1_ratio=0.5, penalty=l2, solver=saga; total time=   1.0s\n",
      "[CV] END .........C=1, l1_ratio=0.5, penalty=l2, solver=saga; total time=   1.0s\n",
      "[CV] END .C=1, l1_ratio=0.5, penalty=elasticnet, solver=saga; total time=  20.1s\n",
      "[CV] END .........C=1, l1_ratio=0.7, penalty=l1, solver=saga; total time=  18.3s\n",
      "[CV] END ........C=10, l1_ratio=0.1, penalty=l1, solver=saga; total time= 1.1min\n",
      "[CV] END C=10, l1_ratio=0.1, penalty=elasticnet, solver=saga; total time= 2.8min\n",
      "[CV] END ........C=10, l1_ratio=0.7, penalty=l1, solver=saga; total time= 1.1min\n",
      "[CV] END C=10, l1_ratio=0.7, penalty=elasticnet, solver=saga; total time= 1.8min\n",
      "[CV] END .......C=100, l1_ratio=0.1, penalty=l1, solver=saga; total time= 2.9min\n",
      "[CV] END .......C=100, l1_ratio=0.5, penalty=l1, solver=saga; total time= 2.9min\n",
      "[CV] END C=100, l1_ratio=0.5, penalty=elasticnet, solver=saga; total time= 3.7min\n",
      "[CV] END C=100, l1_ratio=0.7, penalty=elasticnet, solver=saga; total time= 2.9min\n"
     ]
    }
   ],
   "source": [
    "# Ensure the directories exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('result', exist_ok=True)\n",
    "\n",
    "# Save the trained models\n",
    "joblib.dump(best_rf, 'models/random_forest_model.pkl')\n",
    "joblib.dump(best_svc, 'models/svc_model.pkl')\n",
    "joblib.dump(best_logreg, 'models/logistic_regression_model.pkl')\n",
    "\n",
    "# Determine the best model based on accuracy\n",
    "best_model_name = max(best_model_info, key=lambda model: best_model_info[model]['accuracy'])\n",
    "best_model_params = best_model_info[best_model_name]['best_hyperparams']\n",
    "best_model_accuracy = best_model_info[best_model_name]['accuracy']\n",
    "\n",
    "# Write best model parameters and metrics to a text file\n",
    "result_text = (\n",
    "    f\"Best Model: {best_model_name}\\n\"\n",
    "    f\"Best Hyperparameters: {best_model_params}\\n\"\n",
    "    f\"Test Accuracy: {best_model_accuracy:.4f}\\n\"\n",
    ")\n",
    "\n",
    "with open('result/best_model_info.txt', 'w') as file:\n",
    "    file.write(result_text)\n",
    "\n",
    "print(f\"\\nModel and results saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44814bf9-4f45-4440-b8bb-02a2614da3d2",
   "metadata": {},
   "source": [
    "# Predicting on the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "01f702ce-938a-4656-8937-314163500199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model based on accuracy\n",
    "best_model_filename = {\n",
    "    'RandomForest': 'models/random_forest_model.pkl',\n",
    "    'SVC': 'models/svc_model.pkl',\n",
    "    'LogisticRegression': 'models/logistic_regression_model.pkl'\n",
    "}[best_model_name]\n",
    "\n",
    "best_model = joblib.load(best_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c4e8771b-f23d-4318-b50e-fbf76695eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = complete_preprocessing(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc262c1d-6979-400b-bff9-27e1de9815c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fdd373d3-037b-4fbf-9509-69bb2f53087d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions from the best model (SVC):\n",
      "\n",
      "['spam' 'spam' 'spam' ... 'not_spam' 'not_spam' 'spam']\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nPredictions from the best model ({best_model_name}):\\n\")\n",
    "print(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "54d76f1b-8208-40bb-b8c7-6b6032af7d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b4c16282-2934-49c9-ae12-99ad8ca3c960</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cbe49c1c-b328-4716-9b78-9169c6111e80</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0fa05eb2-f8cd-4cbf-b48e-bbc925b2baac</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b696569e-f7de-4771-9946-be5dd477b2f6</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d9bd17c0-28ec-43f2-b29a-2b9f25089a85</td>\n",
       "      <td>not_spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13539</th>\n",
       "      <td>c03b5042-4fbd-4756-86aa-7edd82777094</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13540</th>\n",
       "      <td>39841b62-79c2-4b9f-b00d-a72902490244</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13541</th>\n",
       "      <td>d5af0144-7b08-4695-8269-5b1507816b91</td>\n",
       "      <td>not_spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13542</th>\n",
       "      <td>65735e11-cf67-4739-964e-67b1021c7153</td>\n",
       "      <td>not_spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13543</th>\n",
       "      <td>ee8a009c-def7-4b71-9550-69482fc6552d</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13544 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id_     class\n",
       "0      b4c16282-2934-49c9-ae12-99ad8ca3c960      spam\n",
       "1      cbe49c1c-b328-4716-9b78-9169c6111e80      spam\n",
       "2      0fa05eb2-f8cd-4cbf-b48e-bbc925b2baac      spam\n",
       "3      b696569e-f7de-4771-9946-be5dd477b2f6      spam\n",
       "4      d9bd17c0-28ec-43f2-b29a-2b9f25089a85  not_spam\n",
       "...                                     ...       ...\n",
       "13539  c03b5042-4fbd-4756-86aa-7edd82777094      spam\n",
       "13540  39841b62-79c2-4b9f-b00d-a72902490244      spam\n",
       "13541  d5af0144-7b08-4695-8269-5b1507816b91  not_spam\n",
       "13542  65735e11-cf67-4739-964e-67b1021c7153  not_spam\n",
       "13543  ee8a009c-def7-4b71-9550-69482fc6552d      spam\n",
       "\n",
       "[13544 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   3.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   3.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   3.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=300; total time=   6.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   3.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   2.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   4.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   4.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   7.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   2.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=   2.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   2.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   5.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   4.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=   4.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   7.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   7.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  13.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  11.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   1.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  11.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   2.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=   4.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   2.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   2.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   7.0s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=   7.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=   5.0s\n",
      "[CV] END ........C=100, degree=2, gamma=0.001, kernel=linear; total time=  10.1s\n",
      "[CV] END ............C=0.1, degree=3, gamma=0.01, kernel=rbf; total time= 1.2min\n",
      "[CV] END ................C=10, degree=4, gamma=1, kernel=rbf; total time= 3.1min\n",
      "[CV] END ............C=100, degree=4, gamma=1, kernel=linear; total time=  12.5s\n",
      "[CV] END ...........C=1, degree=4, gamma=0.01, kernel=linear; total time=  15.0s\n",
      "[CV] END .........C=0.1, degree=3, gamma=0.01, kernel=linear; total time=  27.4s\n",
      "[CV] END ..........C=10, degree=2, gamma=0.01, kernel=linear; total time=  12.1s\n",
      "[CV] END ...............C=100, degree=4, gamma=1, kernel=rbf; total time= 3.2min\n",
      "[CV] END ............C=100, degree=3, gamma=0.1, kernel=poly; total time=  14.0s\n",
      "[CV] END ................C=10, degree=2, gamma=1, kernel=rbf; total time= 3.1min\n",
      "[CV] END ..........C=100, degree=2, gamma=0.001, kernel=poly; total time= 1.3min\n",
      "[CV] END ..........C=1, degree=2, gamma=0.001, kernel=linear; total time=  13.8s\n",
      "[CV] END ..........C=1, degree=2, gamma=0.001, kernel=linear; total time=  14.0s\n",
      "[CV] END ........C=0.1, degree=2, gamma=0.001, kernel=linear; total time=  26.2s\n",
      "[CV] END ..............C=0.1, degree=4, gamma=1, kernel=poly; total time=  20.8s\n",
      "[CV] END ..............C=0.1, degree=4, gamma=1, kernel=poly; total time=  21.4s\n",
      "[CV] END .............C=100, degree=3, gamma=0.1, kernel=rbf; total time=  20.0s\n",
      "[CV] END ...............C=10, degree=4, gamma=1, kernel=poly; total time=  14.5s\n",
      "[CV] END ..............C=1, degree=2, gamma=1, kernel=linear; total time=  13.9s\n",
      "[CV] END ..............C=1, degree=2, gamma=1, kernel=linear; total time=  13.7s\n",
      "[CV] END .............C=0.1, degree=3, gamma=0.1, kernel=rbf; total time=  59.3s\n",
      "[CV] END ...........C=0.1, degree=2, gamma=0.001, kernel=rbf; total time= 1.4min\n",
      "[CV] END ............C=100, degree=3, gamma=0.01, kernel=rbf; total time=  14.0s\n",
      "[CV] END ..............C=1, degree=4, gamma=1, kernel=linear; total time=  14.0s\n",
      "[CV] END .............C=10, degree=3, gamma=1, kernel=linear; total time=  12.1s\n",
      "[CV] END .............C=10, degree=3, gamma=1, kernel=linear; total time=  11.4s\n",
      "[CV] END .............C=0.1, degree=4, gamma=0.1, kernel=rbf; total time=  59.2s\n",
      "[CV] END ............C=0.1, degree=4, gamma=1, kernel=linear; total time=  25.7s\n",
      "[CV] END ..........C=0.1, degree=3, gamma=0.001, kernel=poly; total time= 1.7min\n",
      "[CV] END .......C=0.1, l1_ratio=0.1, penalty=l2, solver=saga; total time=   1.2s\n",
      "[CV] END .......C=0.1, l1_ratio=0.1, penalty=l2, solver=saga; total time=   1.1s\n",
      "[CV] END C=0.1, l1_ratio=0.1, penalty=elasticnet, solver=saga; total time=  25.8s\n",
      "[CV] END .........C=1, l1_ratio=0.1, penalty=l2, solver=saga; total time=   0.9s\n",
      "[CV] END .C=1, l1_ratio=0.1, penalty=elasticnet, solver=saga; total time=  47.5s\n",
      "[CV] END .........C=1, l1_ratio=0.7, penalty=l1, solver=saga; total time=  17.8s\n",
      "[CV] END .........C=1, l1_ratio=0.7, penalty=l2, solver=saga; total time=   1.1s\n",
      "[CV] END .........C=1, l1_ratio=0.7, penalty=l2, solver=saga; total time=   1.0s\n",
      "[CV] END .........C=1, l1_ratio=0.7, penalty=l2, solver=saga; total time=   1.1s\n",
      "[CV] END .C=1, l1_ratio=0.7, penalty=elasticnet, solver=saga; total time=  20.9s\n",
      "[CV] END ........C=10, l1_ratio=0.1, penalty=l2, solver=saga; total time=   3.3s\n",
      "[CV] END ........C=10, l1_ratio=0.1, penalty=l2, solver=saga; total time=   2.8s\n",
      "[CV] END C=10, l1_ratio=0.1, penalty=elasticnet, solver=saga; total time= 2.9min\n",
      "[CV] END C=10, l1_ratio=0.5, penalty=elasticnet, solver=saga; total time= 2.2min\n",
      "[CV] END C=10, l1_ratio=0.7, penalty=elasticnet, solver=saga; total time= 1.7min\n",
      "[CV] END .......C=100, l1_ratio=0.1, penalty=l2, solver=saga; total time=   4.5s\n",
      "[CV] END C=100, l1_ratio=0.1, penalty=elasticnet, solver=saga; total time= 4.1min\n",
      "[CV] END .......C=100, l1_ratio=0.5, penalty=l1, solver=saga; total time= 3.0min\n",
      "[CV] END .......C=100, l1_ratio=0.7, penalty=l1, solver=saga; total time= 2.9min\n",
      "[CV] END C=100, l1_ratio=0.7, penalty=elasticnet, solver=saga; total time= 2.7min\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"id_\": df_test[\"id_\"],\n",
    "    \"class\": y_pred_test\n",
    "}\n",
    "submission_df = pd.DataFrame(data)\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fae7cf8d-d2a8-4bbf-8b3d-b95f0feafce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"result/submission_Md_Rittique_alam.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d659b7cf-92e7-491f-a4b4-4a3e4c76f7d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
